{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf601df-86a7-4d4a-bee9-90c43524fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(r\"C:\\Users\\nanda\\Learn\\RAG_new\\.env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381093a0-dc6f-4854-9872-c2eee65aedaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Bot reply:\n",
      " \"Columbia\" can refer to several places, but the most common references are:\n",
      "\n",
      "1. **Colombia**: A country in South America, bordered by Venezuela to the east, Brazil to the southeast, Peru to the south, Ecuador and the Pacific Ocean to the west, and the Caribbean Sea to the north.\n",
      "\n",
      "2. **District of Columbia (Washington, D.C.)**: The capital of the United States, located on the east coast of the country between Maryland and Virginia.\n",
      "\n",
      "3. **Columbia University**: An Ivy League university located in New York City.\n",
      "\n",
      "4. **Columbia, South Carolina**: The capital city of the state of South Carolina in the United States.\n",
      "\n",
      "If you have a specific \"Columbia\" in mind, please provide more context!\n"
     ]
    }
   ],
   "source": [
    " # Import the LangChain interface for OpenAI chat models\n",
    "from langchain_openai import ChatOpenAI        \n",
    "\n",
    "# Create a GPT‚Äë4o‚Äëmini chatbot with deterministic output (temperature‚ÄØ=‚ÄØ0)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)  \n",
    "\n",
    "# Prompt the learner to type a question and store it in the variable `prompt`\n",
    "prompt = input(\"‚ùì Your question for the bot: \")        \n",
    "\n",
    "# Send the user‚Äôs question to the language model and save the response as `response`\n",
    "response = llm.invoke(prompt)                         \n",
    "\n",
    "# Display the model‚Äôs answer in a readable format\n",
    "print(\"\\nü§ñ Bot reply:\\n\", response.content)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6903c154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000016EAF2C5610>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000016EAF78DE10>, root_client=<openai.OpenAI object at 0x0000016EAF2C4AD0>, root_async_client=<openai.AsyncOpenAI object at 0x0000016EAF78D910>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8367badd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'where is columbia'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91447163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Columbia\" can refer to several places, but the most common references are:\\n\\n1. **Colombia**: A country in South America, bordered by Venezuela to the east, Brazil to the southeast, Peru to the south, Ecuador and the Pacific Ocean to the west, and the Caribbean Sea to the north.\\n\\n2. **District of Columbia (Washington, D.C.)**: The capital of the United States, located on the east coast of the country between Maryland and Virginia.\\n\\n3. **Columbia University**: An Ivy League university located in New York City.\\n\\n4. **Columbia, South Carolina**: The capital city of the state of South Carolina in the United States.\\n\\nIf you have a specific \"Columbia\" in mind, please provide more context!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 157, 'prompt_tokens': 11, 'total_tokens': 168, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f4ae844694', 'id': 'chatcmpl-D9YUXjamuhmO0PhTiWz0CVRrIyscx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bf6945dd-3ab6-49cc-9af3-d9ee83caac21-0', usage_metadata={'input_tokens': 11, 'output_tokens': 157, 'total_tokens': 168, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49bdd5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Columbia\" can refer to several places, but the most common references are:\\n\\n1. **Colombia**: A country in South America, bordered by Venezuela to the east, Brazil to the southeast, Peru to the south, Ecuador and the Pacific Ocean to the west, and the Caribbean Sea to the north.\\n\\n2. **District of Columbia (Washington, D.C.)**: The capital of the United States, located on the east coast of the country between Maryland and Virginia.\\n\\n3. **Columbia University**: An Ivy League university located in New York City.\\n\\n4. **Columbia, South Carolina**: The capital city of the state of South Carolina in the United States.\\n\\nIf you have a specific \"Columbia\" in mind, please provide more context!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2fc246f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 157,\n",
       "  'prompt_tokens': 11,\n",
       "  'total_tokens': 168,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
       " 'system_fingerprint': 'fp_f4ae844694',\n",
       " 'id': 'chatcmpl-D9YUXjamuhmO0PhTiWz0CVRrIyscx',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bbdb8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run--bf6945dd-3ab6-49cc-9af3-d9ee83caac21-0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968cae48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 11,\n",
       " 'output_tokens': 157,\n",
       " 'total_tokens': 168,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8a9f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Bot reply:\n",
      " \"Tacky\" is a term that describes something that is considered to be in poor taste, gaudy, or overly flashy‚Äîlike wearing socks with sandals to a fancy dinner or decorating your home with a life-sized statue of a flamingo wearing sunglasses. It‚Äôs that cringe-worthy moment when you realize your friend‚Äôs idea of ‚Äústylish‚Äù is a neon green jumpsuit with sequins. \n",
      "\n",
      "In essence, if something is tacky, it‚Äôs like that one relative who shows up to family gatherings wearing a Hawaiian shirt in the middle of winter‚Äîeveryone notices, and not in a good way! So, if you ever find yourself questioning whether something is tacky, just ask yourself: ‚ÄúWould I want my grandma to see me in this?‚Äù If the answer is a resounding ‚Äúno,‚Äù then congratulations, you‚Äôve just identified something tacky! üéâ\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1. LLM\n",
    "llm = init_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    model_provider=\"openai\",  \n",
    ")\n",
    "\n",
    "# 2. Prompt preparation\n",
    "prompt = PromptTemplate.from_template(\"Answer the following question as helpfully as possible with some funny elements:\\n\\n{question}\")\n",
    "\n",
    "# 3. dynamic Prompt insertion \n",
    "formatted_prompt = prompt.invoke({\"question\": input(\"‚ùì Your question for the bot: \")})\n",
    "\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "print(\"\\nü§ñ Bot reply:\\n\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354677fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.prompt.PromptTemplate"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce92c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompt_values.StringPromptValue"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935c66c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question as helpfully as possible with some funny elements:\n",
      "\n",
      "what is valentines day\n"
     ]
    }
   ],
   "source": [
    "print(formatted_prompt.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4c7abd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.StringPromptValue'>\n",
      "['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_on_complete__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'copy', 'dict', 'from_orm', 'get_lc_namespace', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'text', 'to_json', 'to_json_not_implemented', 'to_messages', 'to_string', 'type', 'update_forward_refs', 'validate']\n",
      "Answer the following question as helpfully as possible with some funny elements:\n",
      "\n",
      "what is valentines day\n"
     ]
    }
   ],
   "source": [
    "# Check the type\n",
    "print(type(formatted_prompt))\n",
    "\n",
    "# List all attributes\n",
    "print(dir(formatted_prompt))\n",
    "\n",
    "# Try accessing .text anyway\n",
    "print(formatted_prompt.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80179401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a business analyst and helpful assistant answering questions correct with some anger.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is the IRR?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a business analyst and helpful assistant answering questions correct with {style}.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "\n",
    "formatted_prompt = prompt.invoke({\"style\": \"some anger\", \"question\": \"What is the IRR?\"}).messages\n",
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "694784db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Beauty is the harmony of form, color, and emotional resonance.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 31, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f4ae844694', 'id': 'chatcmpl-D9offSSVJfvp3XBkaz8THC6JJXyMV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--126ff5aa-45e3-4e02-b34b-4198e2e2e8a8-0', usage_metadata={'input_tokens': 31, 'output_tokens': 13, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"gpt-4o-mini\", temperature=0, model_provider=\"openai\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a business analyst and helpful assistant answering questions correct with {style}.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "formatted_prompt = prompt.invoke({\"style\": \"sweet\", \"question\": \"What is the IRR?\"}).messages\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm \n",
    "response = chain.invoke({\"style\": \"sweet\", \"question\": input(\"‚ùì Your question for the bot: \")})\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b7f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
